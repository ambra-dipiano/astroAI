{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b75d0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maps: dict_keys(['DS', 'LABELS'])\n",
      "DS dataset size: 20000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import join, isfile, expandvars\n",
    "\n",
    "# data\n",
    "zenith = 'random' # 'z20'  \n",
    "table = 'regressor_5sgm_xy_flip.pickle'\n",
    "path = f'{expandvars(\"$HOME\")}/E4/irf_{zenith}/crab/'\n",
    "dataset = join(path, table)\n",
    "\n",
    "# dataset \n",
    "if '.pickle' in table:\n",
    "    with open(dataset,'rb') as f: ds = pickle.load(f)\n",
    "    infotable = join(path, table.replace('.pickle', '.dat'))\n",
    "elif '.npy' in table:\n",
    "    ds = np.load(dataset, allow_pickle=True, encoding='latin1', fix_imports=True).flat[0]\n",
    "    infotable = join(path, table.replace('.npy', '.dat'))\n",
    "\n",
    "if '_CLEAN' in infotable:\n",
    "    infotable = infotable.replace('_CLEAN', '')\n",
    "    \n",
    "print(f\"Maps: {ds.keys()}\")\n",
    "print(f\"DS dataset size: {len(ds['DS'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "627ac6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 200, 200) (16000, 2)\n",
      "Train dataset: 16000, (16000, 200, 200, 1)\n",
      "Train labels: 16000, (16000, 2)\n",
      "\n",
      "Test dataset: 4000, (4000, 200, 200, 1)\n",
      "Test labels: 4000, (4000, 2)\n"
     ]
    }
   ],
   "source": [
    "from astroai.tools.utils import split_regression_dataset\n",
    "\n",
    "binning = 200\n",
    "train_data, train_labels, test_data, test_labels = split_regression_dataset(ds, split=80, reshape=True, binning=binning)\n",
    "\n",
    "print(f\"Train dataset: {len(train_data)}, {train_data.shape}\")\n",
    "print(f\"Train labels: {len(train_labels)}, {train_labels.shape}\")\n",
    "print(f\"\\nTest dataset: {len(test_data)}, {test_data.shape}\")\n",
    "print(f\"Test labels: {len(test_labels)}, {test_labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "629f9e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>seed</th>\n",
       "      <th>start</th>\n",
       "      <th>stop</th>\n",
       "      <th>duration</th>\n",
       "      <th>source_ra</th>\n",
       "      <th>source_dec</th>\n",
       "      <th>point_ra</th>\n",
       "      <th>point_dec</th>\n",
       "      <th>offset</th>\n",
       "      <th>irf</th>\n",
       "      <th>fov</th>\n",
       "      <th>sim_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24485</th>\n",
       "      <td>crab_19486</td>\n",
       "      <td>19486</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>223.353437</td>\n",
       "      <td>56.771868</td>\n",
       "      <td>222.569617</td>\n",
       "      <td>56.498674</td>\n",
       "      <td>0.510349</td>\n",
       "      <td>North_z60_5h_LST</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.628982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name   seed  start  stop  duration   source_ra  source_dec  \\\n",
       "24485  crab_19486  19486      0   100       100  223.353437   56.771868   \n",
       "\n",
       "         point_ra  point_dec    offset               irf  fov  sim_time  \n",
       "24485  222.569617  56.498674  0.510349  North_z60_5h_LST  2.5  6.628982  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from astroai.tools.utils import plot_heatmap, set_wcs\n",
    "\n",
    "# get random seed\n",
    "idx = np.random.choice(range(len(test_data)))\n",
    "# find seed to get the original heatmap\n",
    "seed = len(train_data) + idx + 1\n",
    "\n",
    "# get simulation data\n",
    "infodata = pd.read_csv(infotable, sep=' ', header=0).sort_values(by=['seed'])\n",
    "row = infodata[infodata['seed']==seed]\n",
    "row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916fda5",
   "metadata": {},
   "source": [
    "# Load model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1858f673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 14:42:49.658740: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-03 14:42:49.658779: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-03 14:42:49.658790: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-03 14:42:49.778227: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-03 14:43:02.399770: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:268] failed call to cuInit: CUDA_ERROR_INVALID_DEVICE: invalid device ordinal\n",
      "2024-07-03 14:43:02.399831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: kingarthur\n",
      "2024-07-03 14:43:02.399879: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: kingarthur\n",
      "2024-07-03 14:43:02.400052: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 470.239.6\n",
      "2024-07-03 14:43:02.400084: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 470.239.6\n",
      "2024-07-03 14:43:02.400092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 470.239.6\n",
      "2024-07-03 14:43:02.796023: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1060320000 exceeds 10% of free system memory.\n",
      "2024-07-03 14:43:02.921056: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1060320000 exceeds 10% of free system memory.\n",
      "2024-07-03 14:43:02.956163: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1060320000 exceeds 10% of free system memory.\n",
      "2024-07-03 14:43:09.275735: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1060320000 exceeds 10% of free system memory.\n",
      "2024-07-03 14:43:10.017566: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 1060320000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 197, 197, 6)       102       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 98, 98, 6)         0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 97, 97, 12)        300       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 96, 96, 12)        588       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 95, 95, 12)        588       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 94, 94, 12)        588       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 47, 47, 12)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 47, 47, 12)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 26508)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10000)             265090000 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10000)             0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 20002     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 265112168 (1011.32 MB)\n",
      "Trainable params: 265112168 (1011.32 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "savename = 'regressor_5sgm_filter6_4convs_dense1e4_z20' \n",
    "model = tf.keras.models.load_model(f'../models/cnn_regressor/{savename}.keras')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6aadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 7 µs, total: 15 µs\n",
      "Wall time: 29.8 µs\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "predictions = model.predict(test_data) * binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025030c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[idx], test_labels[idx] * binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b1cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroai.tools.utils import *\n",
    "\n",
    "binning = 200\n",
    "pixelsize = (2 * row['fov'].values[0]) / binning\n",
    "point_ref = (binning / 2) + (pixelsize / 2)\n",
    "w = set_wcs(point_ra=row['point_ra'].values[0], point_dec=row['point_dec'].values[0], \n",
    "            point_ref=point_ref, pixelsize=pixelsize)\n",
    "\n",
    "# TRUE\n",
    "true_sky = SkyCoord(ra=row['source_ra'].values[0], dec=row['source_dec'].values[0], unit='deg', frame='icrs')\n",
    "x, y = w.world_to_pixel(true_sky) \n",
    "true_sky = true_sky.ra.deg, true_sky.dec.deg\n",
    "true_pix = x, y\n",
    "\n",
    "# LABEL\n",
    "label_pix = test_labels[idx][0] * binning, test_labels[idx][1] * binning\n",
    "sky = w.pixel_to_world(label_pix[0], label_pix[1])\n",
    "label_sky = sky.ra.deg, sky.dec.deg\n",
    "\n",
    "# PREDICTION\n",
    "pred_pix = predictions[idx]\n",
    "sky = w.pixel_to_world(pred_pix[0], pred_pix[1])\n",
    "pred_sky = sky.ra.deg, sky.dec.deg\n",
    "\n",
    "\n",
    "print(f'SEED: {seed}')\n",
    "print('---- PIX')\n",
    "print(f\"true: {true_pix}\")\n",
    "print(f\"label: {label_pix}\")\n",
    "print(f\"prediction: {pred_pix}\")\n",
    "print('---- SKY')\n",
    "print(f\"true: {true_sky} \")\n",
    "print(f\"label: {label_sky}\")\n",
    "print(f\"prediction: {pred_sky}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a3aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "radius_deg = 0.2\n",
    "radius_pix = radius_deg/0.025\n",
    "figsize = (10, 10)\n",
    "histsize = (10, 8)\n",
    "fs = 16\n",
    "sz = 1.5e3\n",
    "\n",
    "# LEGENDS\n",
    "custom_lines = [Line2D([0], [0], color='k', lw=1, ls='-.'),\n",
    "                Line2D([0], [0], color='r', lw=1, ls='-'),\n",
    "                Line2D([0], [0], color='w', lw=1, ls='--')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9323bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIX\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "img = ax.imshow(test_data[idx], vmin=0, vmax=1)\n",
    "ax.add_patch(plt.Circle((true_pix), radius=radius_pix, edgecolor='k', facecolor='none', ls='-.'))\n",
    "ax.add_patch(plt.Circle((pred_pix), radius=radius_pix, edgecolor='r', facecolor='none', ls='-'))\n",
    "ax.set_ylabel('y [pixels]', fontsize=fs)\n",
    "ax.set_xlabel('x [pixels]', fontsize=fs)\n",
    "#ax.set_title(f'counts map coordinates {seed}', fontsize=fs)\n",
    "ax.legend(custom_lines[:2], ['true', 'prediction'], fontsize=fs)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/regressor_{seed}_pix.png')\n",
    "plt.show()\n",
    "\n",
    "# SKY\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111, projection=w)\n",
    "\n",
    "img = ax.imshow(test_data[idx], vmin=0, vmax=1)\n",
    "ax.coords['ra'].set_format_unit(u.deg)\n",
    "ax.coords['dec'].set_format_unit(u.deg)\n",
    "ax.scatter(true_sky[0], true_sky[1], transform=ax.get_transform('icrs'), s=sz,\n",
    "           edgecolor='k', facecolor='none', ls='-.')\n",
    "ax.scatter(pred_sky[0], pred_sky[1], transform=ax.get_transform('icrs'), s=sz,\n",
    "           edgecolor='r', facecolor='none', ls='-')\n",
    "ax.set_ylabel('Right Ascension [deg]', fontsize=fs)\n",
    "ax.set_xlabel('RA [deg]', fontsize=fs)\n",
    "#ax.set_title(f'counts map {seed}', fontsize=fs)\n",
    "ax.legend(custom_lines[:2], ['true', 'prediction'], fontsize=fs)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/regressor_{seed}_sky.png')\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b082a18",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c880dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.evaluate(test_data, test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda75693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = np.load(f'../models/cnn_regressor/{savename}_history.npy', \n",
    "                  allow_pickle='TRUE').item()\n",
    "\n",
    "# LOSS\n",
    "fig, ax = plt.subplots(figsize=histsize)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "ax.plot(history['loss'], label='training', ls='--', lw=2)\n",
    "ax.plot(history['val_loss'], label = 'validation', ls='-.', lw=2)\n",
    "ax.set_xlabel('Epoch', fontsize=fs)\n",
    "ax.set_ylabel('Loss', fontsize=fs)\n",
    "ax.set_title('loss function', fontsize=fs*1.5)\n",
    "ax.set_ylim([0.0,0.2])\n",
    "ax.grid()\n",
    "ax.legend(fontsize=fs)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f'img/regressor_loss.png')\n",
    "\n",
    "# ACCURACY\n",
    "fig, ax = plt.subplots(figsize=histsize)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "ax.plot(history['accuracy'], label='training', ls='--', lw=2)\n",
    "ax.plot(history['val_accuracy'], label = 'validation', ls='-.', lw=2)\n",
    "ax.set_xlabel('Epoch', fontsize=fs)\n",
    "ax.set_ylabel('Accuracy', fontsize=fs)\n",
    "ax.set_title('accuracy', fontsize=fs*1.5)\n",
    "ax.set_ylim([0.5,1])\n",
    "ax.grid()\n",
    "ax.legend(fontsize=fs)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f'img/regressor_accuracy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52eb20d7",
   "metadata": {},
   "source": [
    "# Get separation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53a5f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroai.tools.utils import *\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# get true coordinates in SkyCoord\n",
    "true = SkyCoord(ra=row['source_ra'].values[0], dec=row['source_dec'].values[0], unit='deg', frame='icrs')\n",
    "\n",
    "# get errors\n",
    "err = true.separation(sky)\n",
    "\n",
    "print(f\"TRUE: ({true.ra.deg}, {true.dec.deg})\\n\")\n",
    "print(f\"PREDICTION: ({sky.ra.deg}, {sky.dec.deg})\\n\")\n",
    "print(f\"ERROR: {err.deg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de99ba4",
   "metadata": {},
   "source": [
    "# Get DS separation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e21677",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = []\n",
    "s = len(train_data)\n",
    "for pred, label in zip(predictions, test_labels):\n",
    "    s += 1 \n",
    "    row = infodata[infodata['seed']==s]\n",
    "    # WCS coordinates\n",
    "    w = set_wcs(point_ra=row['point_ra'].values[0], point_dec=row['point_dec'].values[0], \n",
    "                point_ref=point_ref, pixelsize=pixelsize)\n",
    "    # simulated coordinates\n",
    "    true_deg = {'ra': row['source_ra'].values[0], 'dec': row['source_dec'].values[0]}\n",
    "    true_pix = {'x': label[0], 'y': label[1]}\n",
    "    # prediction coordinates\n",
    "    sky = w.pixel_to_world(pred[0], pred[1])\n",
    "    found_deg = {'ra': sky.ra.deg, 'dec': sky.dec.deg}\n",
    "    # find separation in data\n",
    "    true_sky = SkyCoord(ra=true_deg['ra'], dec=true_deg['dec'], unit='deg', frame='icrs')\n",
    "    found_sky = SkyCoord(ra=found_deg['ra'], dec=found_deg['dec'], unit='deg', frame='icrs')\n",
    "    err.append(true_sky.separation(found_sky))\n",
    "\n",
    "err_noisy = [e.degree for e in err]\n",
    "len(err_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026edcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=histsize)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "\n",
    "# cumulative counts hist\n",
    "data = err_noisy\n",
    "#ax.set_title('reconstruction error', fontsize=fs*1.5)\n",
    "ax.hist(data, 50, density=False, histtype='step', color='g', label=['noisy model'])\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('angular separation (deg)', fontsize=fs)\n",
    "ax.grid()\n",
    "ax.legend(fontsize=fs)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f'img/regressor_loc_error_noisy.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffaaed6",
   "metadata": {},
   "source": [
    "# Compare with second model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52623946",
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = 'regressor_5sgm_filter6_4convs_dense1e4_z20' \n",
    "model = tf.keras.models.load_model(f'../models/cnn_regressor/{savename}.keras')\n",
    "model.summary()\n",
    "\n",
    "# predictions\n",
    "predictions = model.predict(test_data) * binning\n",
    "predictions[idx], test_labels[idx] * binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7731f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = []\n",
    "s = len(train_data)\n",
    "for pred, label in zip(predictions, test_labels):\n",
    "    s += 1 \n",
    "    row = infodata[infodata['seed']==s]\n",
    "    # WCS coordinates\n",
    "    w = set_wcs(point_ra=row['point_ra'].values[0], point_dec=row['point_dec'].values[0], \n",
    "                point_ref=point_ref, pixelsize=pixelsize)\n",
    "    # simulated coordinates\n",
    "    true_deg = {'ra': row['source_ra'].values[0], 'dec': row['source_dec'].values[0]}\n",
    "    true_pix = {'x': label[0], 'y': label[1]}\n",
    "    # prediction coordinates\n",
    "    sky = w.pixel_to_world(pred[0], pred[1])\n",
    "    found_deg = {'ra': sky.ra.deg, 'dec': sky.dec.deg}\n",
    "    # find separation in data\n",
    "    true_sky = SkyCoord(ra=true_deg['ra'], dec=true_deg['dec'], unit='deg', frame='icrs')\n",
    "    found_sky = SkyCoord(ra=found_deg['ra'], dec=found_deg['dec'], unit='deg', frame='icrs')\n",
    "    err.append(true_sky.separation(found_sky))\n",
    "    \n",
    "err_2nd = [e.degree for e in err]\n",
    "len(err_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3375f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=histsize)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "\n",
    "# cumulative counts hist\n",
    "data = err_2nd\n",
    "#ax.set_title('reconstruction error', fontsize=fs*1.5)\n",
    "ax.hist(data, 50, density=False, histtype='step', color='g', label=['cleaned model'])\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('angular separation (deg)', fontsize=fs)\n",
    "ax.grid()\n",
    "ax.legend(fontsize=fs)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f'img/regressor_loc_error_clean.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47748628",
   "metadata": {},
   "source": [
    "# Comparison hist\n",
    "\n",
    "Model yx is the one with better improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d0df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "colors = ['darkblue', 'crimson'] \n",
    "labels = ['z20', 'zALL']\n",
    "hatches = ['\\\\', '//']\n",
    "legends = [mpatches.Patch(facecolor='none', edgecolor=colors[0], hatch=hatches[0]), \n",
    "           mpatches.Patch(facecolor='none', edgecolor=colors[1], hatch=hatches[1])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=histsize)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "\n",
    "# cumulative counts hist\n",
    "data = (err_noisy, err_2nd)\n",
    "#ax.set_title('localisation error', fontsize=fs*1.5)\n",
    "n, bins, patches = ax.hist(data, 50, density=False, histtype='step', color=colors, label=labels)\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('angular separation (deg)', fontsize=fs)\n",
    "ax.grid()\n",
    "ax.legend(handles=legends, labels=labels, fontsize=fs)\n",
    "\n",
    "for patch, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch, hatch=hatch)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f'img/regressor_loc_error_noisy_vs_clean.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149ae637",
   "metadata": {},
   "source": [
    "# Gammapy comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158df322",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammafile = f'{path}/regressor_5sgm_z20_xy_flip_gammapy.txt'\n",
    "gammadata = pd.read_csv(gammafile, sep=' ', header=0).sort_values(by=['seed'])\n",
    "gammadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6507c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "err = []\n",
    "seeds = gammadata['seed']\n",
    "for i, seed in enumerate(seeds):\n",
    "    row = infodata[infodata['seed']==seed]\n",
    "    grow = gammadata[gammadata['seed']==seed]\n",
    "    # WCS coordinates\n",
    "    w = set_wcs(point_ra=row['point_ra'].values[0], point_dec=row['point_dec'].values[0], \n",
    "                point_ref=point_ref, pixelsize=pixelsize)\n",
    "    # simulated coordinates\n",
    "    true_deg = {'ra': row['source_ra'].values[0], 'dec': row['source_dec'].values[0]}\n",
    "    # found coordinates\n",
    "    found_deg = {'ra': grow['loc_ra'].values[0], 'dec': grow['loc_dec'].values[0]}\n",
    "    # find separation in data\n",
    "    true_sky = SkyCoord(ra=true_deg['ra'], dec=true_deg['dec'], unit='deg', frame='icrs')\n",
    "    found_sky = SkyCoord(ra=found_deg['ra'], dec=found_deg['dec'], unit='deg', frame='icrs')\n",
    "    err.append(true_sky.separation(found_sky))\n",
    "    \n",
    "err_gamma = [e.degree for e in err]\n",
    "len(err_noisy[2000:]), len(err_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (err_noisy, err_clean, err_gamma)\n",
    "data = (err_noisy[2000:], err_gamma)\n",
    "\n",
    "colors = ['darkblue', 'deepskyblue']\n",
    "hatches = ['\\\\', '//']\n",
    "labels = ['cnn', 'gammapy']\n",
    "legends = [mpatches.Patch(facecolor='none', edgecolor=colors[0], hatch=hatches[0]), \n",
    "           mpatches.Patch(facecolor='none', edgecolor=colors[1], hatch=hatches[1])]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=histsize)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "\n",
    "# cumulative counts hist\n",
    "#ax.set_title('localisation error', fontsize=fs*1.5)\n",
    "n, bins, patches = ax.hist(data, 50, density=False, histtype='step', color=colors, label=['cnn', 'gammapy'])\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('angular separation (deg)', fontsize=fs)\n",
    "ax.grid()\n",
    "ax.legend(handles=legends, labels=labels, fontsize=fs)\n",
    "\n",
    "for patch, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch, hatch=hatch)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f'img/regressor_loc_error_cnn_vs_gp.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b6332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea15d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8aca04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5309b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astroai",
   "language": "python",
   "name": "astroai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
