{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2474ea2",
   "metadata": {},
   "source": [
    "# CNN model to detect anc localise sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1b3656",
   "metadata": {},
   "source": [
    "## Collect datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "771670f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: dict_keys(['SRC', 'BKG'])\n",
      "\n",
      "Class SRC data from: /data01/homes/dipiano/E4/crab/sim\n",
      "Class BKG data from: /data01/homes/dipiano/E4/background/sim\n",
      "\n",
      "SRC dataset size: 50000\n",
      "BKG dataset size: 50000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "\n",
    "# info tables\n",
    "src_info = f'/data01/homes/dipiano/E4/crab/sim/merged_data.dat'\n",
    "bkg_info = f'/data01/homes/dipiano/E4/background/sim/merged_data.dat'\n",
    "\n",
    "# datasets path\n",
    "src_dataset_path = f'/data01/homes/dipiano/E4/crab/sim'\n",
    "bkg_dataset_path = f'/data01/homes/dipiano/E4/background/sim'\n",
    "datapath = {'SRC': src_dataset_path, 'BKG': bkg_dataset_path}\n",
    "\n",
    "# datasets files\n",
    "dataset = {'SRC': [], 'BKG': []}\n",
    "classes = dataset.keys()\n",
    "print(f\"Classes: {classes}\\n\")\n",
    "for k in classes:\n",
    "    print(f\"Class {k} data from: {datapath[k]}\")\n",
    "    dataset[k] = sorted([join(datapath[k], f) for f in listdir(datapath[k]) if '.fits' in f and isfile(join(datapath[k], f))])\n",
    "    \n",
    "print(f\"\\nSRC dataset size: {len(dataset['SRC'])}\")\n",
    "print(f\"BKG dataset size: {len(dataset['BKG'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4099a4c9",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e05800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.table import Table\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# extract data utility\n",
    "def extract_heatmap(data, trange, smoothing, nbins):\n",
    "    data = data[(data['TIME'] >= trange[0]) & (data['TIME'] <= trange[1])] \n",
    "    \n",
    "    ra = data['RA'].to_numpy()\n",
    "    dec = data['DEC'].to_numpy()\n",
    "    \n",
    "    heatmap, xe, ye = np.histogram2d(ra, dec, bins=nbins)\n",
    "    heatmap = gaussian_filter(heatmap, sigma=smoothing)\n",
    "    return heatmap.T\n",
    "\n",
    "# set map parameters\n",
    "trange = [0, 50]\n",
    "smoothing = 3\n",
    "pixelsize = 0.02\n",
    "nbins = int(5/pixelsize)\n",
    "\n",
    "# gather data\n",
    "for k in classes:\n",
    "    for idx, f in enumerate(dataset[k]):\n",
    "        heatmap = Table.read(f, hdu=1).to_pandas()\n",
    "        heatmap = extract_heatmap(heatmap, trange, smoothing, nbins)\n",
    "        dataset[k][idx] = heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a346855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astroai",
   "language": "python",
   "name": "astroai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
