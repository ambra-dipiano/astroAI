{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2766b519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: dict_keys(['SRC', 'BKG'])\n",
      "\n",
      "Class SRC data from: /data01/homes/dipiano/E4/crab/sim\n",
      "Class BKG data from: /data01/homes/dipiano/E4/background/sim\n",
      "\n",
      "SRC dataset size: 50000\n",
      "BKG dataset size: 50000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir, makedirs\n",
    "from os.path import join, isfile, basename\n",
    "\n",
    "# info tables\n",
    "src_info = f'/data01/homes/dipiano/E4/crab/sim/merged_data.dat'\n",
    "bkg_info = f'/data01/homes/dipiano/E4/background/sim/merged_data.dat'\n",
    "\n",
    "# datasets path\n",
    "src_dataset_path = f'/data01/homes/dipiano/E4/crab/sim'\n",
    "bkg_dataset_path = f'/data01/homes/dipiano/E4/background/sim'\n",
    "datapath = {'SRC': src_dataset_path, 'BKG': bkg_dataset_path}\n",
    "\n",
    "# datasets files\n",
    "datafiles = {'SRC': [], 'BKG': []}\n",
    "classes = datafiles.keys()\n",
    "print(f\"Classes: {classes}\\n\")\n",
    "for k in classes:\n",
    "    print(f\"Class {k} data from: {datapath[k]}\")\n",
    "    datafiles[k] = sorted([join(datapath[k], f) for f in listdir(datapath[k]) if '.fits' in f and isfile(join(datapath[k], f))])\n",
    "    \n",
    "print(f\"\\nSRC dataset size: {len(datafiles['SRC'])}\")\n",
    "print(f\"BKG dataset size: {len(datafiles['BKG'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eadbfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from astropy.table import Table\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# extract data utility\n",
    "def extract_heatmap(data, trange, smoothing, nbins, save=False, save_name=None):\n",
    "    data = data[(data['TIME'] >= trange[0]) & (data['TIME'] <= trange[1])] \n",
    "    ra = data['RA'].to_numpy()\n",
    "    dec = data['DEC'].to_numpy()\n",
    "    heatmap, xe, ye = np.histogram2d(ra, dec, bins=nbins)\n",
    "    heatmap = gaussian_filter(heatmap, sigma=smoothing)\n",
    "    if save and save_name is not None:\n",
    "        np.save(save_name, heatmap, allow_pickle=True, fix_imports=True)\n",
    "    return heatmap.T\n",
    "\n",
    "# normalise heatmap\n",
    "def normalise_heatmap(heatmap, save=False, save_name=None):\n",
    "    min_value = np.min(heatmap)\n",
    "    max_value = np.max(heatmap)\n",
    "    norm_parameters = {'min': min_value, 'max': max_value}\n",
    "    heatmap = (heatmap - min_value) / (max_value - min_value)\n",
    "    if save and save_name is not None:\n",
    "        np.save(save_name, heatmap, allow_pickle=True, fix_imports=True)\n",
    "    return heatmap\n",
    "\n",
    "# plot heatmap\n",
    "def plot_heatmap(heatmap, title='heatmap', norm='linear', show=False, save=False, save_name=None):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if norm == 'linear':\n",
    "        plt.imshow(heatmap, vmin=0, vmax=1)\n",
    "    elif norm == 'log':\n",
    "        plt.imshow(heatmap, norm=SymLogNorm(1, base=10), vmin=0, vmax=1)\n",
    "    plt.xlabel('x(det) [pixels]')\n",
    "    plt.ylabel('y(det) [pixels]')\n",
    "    plt.colorbar()\n",
    "    if save and save_name is not None:\n",
    "        plt.savefig(save_name)\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e86cd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Load SRC data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1223982d1e374a85af7acd20bd5decf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# map parameters\n",
    "trange = [0, 50]\n",
    "exposure = trange[1] - trange[0]\n",
    "smoothing = 3\n",
    "pixelsize = 0.02\n",
    "nbins = int(5/pixelsize)\n",
    "# execution options\n",
    "plot_data = True\n",
    "show_plot = False\n",
    "save_plot = True\n",
    "normalise_data = True\n",
    "save_map = False\n",
    "save_norm = False\n",
    "# model param\n",
    "class_sample = 50000\n",
    "class_train_sample = 80\n",
    "class_test_sample = class_sample - class_train_sample\n",
    "total_train_size = class_train_sample * 2\n",
    "total_test_size = class_test_sample * 2\n",
    "\n",
    "# image datasets\n",
    "makedirs(join(src_dataset_path, f'img_{exposure}s'), exist_ok=True)\n",
    "makedirs(join(src_dataset_path, f'img_{exposure}s_normed'), exist_ok=True)\n",
    "makedirs(join(bkg_dataset_path, f'img_{exposure}s'), exist_ok=True)\n",
    "makedirs(join(bkg_dataset_path, f'img_{exposure}s_normed'), exist_ok=True)\n",
    "pngpath = {'SRC': join(src_dataset_path, 'img'), 'SRC_NORMED': join(src_dataset_path, 'img_normed'),\n",
    "           'BKG': join(bkg_dataset_path, 'img'), 'BKG_NORMED': join(bkg_dataset_path, 'img_normed')}\n",
    "\n",
    "\n",
    "# gather data\n",
    "datasets = {'SRC': [], 'BKG': []}\n",
    "for k in classes:\n",
    "    print(f\"\\nLoad {k} data...\")\n",
    "    for idx, f in enumerate(tqdm(datafiles[k][:class_sample])):\n",
    "        # load\n",
    "        heatmap = Table.read(f, hdu=1).to_pandas()\n",
    "        # integrate exposure\n",
    "        heatmap = extract_heatmap(heatmap, trange, smoothing, nbins, save=save_map, save_name=datafiles[k][idx].replace('.fits', f'_{exposure}s.npy'))\n",
    "        # plot map\n",
    "        if plot_data:\n",
    "            plot_heatmap(heatmap, title='original', show=show_plot, save=save_plot, save_name=join(pngpath[k], basename(datafiles[k][idx].replace('.fits', f'_{exposure}s.png'))))\n",
    "        # normalise map\n",
    "        if normalise_data:\n",
    "            heatmap = normalise_heatmap(heatmap, save=save_norm, save_name=datafiles[k][idx].replace('.fits', f'_{exposure}s_normed.npy'))\n",
    "        # plot normalised map\n",
    "        if plot_data:\n",
    "            plot_heatmap(heatmap, title='normalised', show=show_plot, save=save_plot, save_name=join(pngpath[f'{k}_NORMED'], basename(datafiles[k][idx].replace('.fits', f'_{exposure}s_normed.png'))))\n",
    "        # add to dataset\n",
    "        datasets[k].append(heatmap)\n",
    "        \n",
    "print(f\"DATASET {datasets.keys()}\")\n",
    "print(f\"Sample SRC maps: {len(datasets['SRC'])}\")\n",
    "print(f\"Sample BKG maps: {len(datasets['BKG'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d6259a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41721e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d86ffc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astroai",
   "language": "python",
   "name": "astroai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
