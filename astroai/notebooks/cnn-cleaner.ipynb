{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b69628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import join, isfile, expandvars\n",
    "\n",
    "# data\n",
    "zenith = 'random' # 'z20' # \n",
    "table = 'cleaner_5sgm.pickle'\n",
    "path = f'{expandvars(\"$HOME\")}/E4/irf_{zenith}/crab/'\n",
    "dataset = join(path, table)\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "# model\n",
    "if zenith == 'random':\n",
    "    cnn_name = 'cleaner_zALL'\n",
    "else:\n",
    "    cnn_name = f'cleaner_{zenith}'\n",
    "\n",
    "# dataset \n",
    "if '.pickle' in table:\n",
    "    with open(dataset,'rb') as f: ds = pickle.load(f)\n",
    "    infofile = join(path, table.replace('.pickle', '.dat'))\n",
    "elif '.npy' in table:\n",
    "    ds = np.load(dataset, allow_pickle=True, encoding='latin1', fix_imports=True).flat[0]\n",
    "    infofile = join(path, table.replace('.npy', '.dat'))\n",
    "\n",
    "print(f\"Classes: {ds.keys()}\\n\")\n",
    "print(f\"NOISY dataset size: {len(ds['DS1'])}\")\n",
    "print(f\"CLEAN dataset size: {len(ds['DS2'])}\")\n",
    "\n",
    "print(ds['DS1'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56afebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroai.tools.utils import split_noisy_dataset\n",
    "\n",
    "train_noisy, train_clean, test_noisy, test_clean = split_noisy_dataset(ds, split=80, reshape=True, binning=200)\n",
    "\n",
    "print(f\"Train clean: {train_clean.shape}\")\n",
    "print(f\"Train noisy: {train_noisy.shape}\")\n",
    "print(f\"\\nTest clean: {test_clean.shape}\")\n",
    "print(f\"Test labenoicyls: {test_noisy.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99417cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "infodata = pd.read_csv(infofile, sep=' ', header=0).sort_values(by=['seed'])\n",
    "infodata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0666f349",
   "metadata": {},
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16754d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(range(len(test_noisy)))\n",
    "idx = 9664 - 8000\n",
    "# find seed to get the original heatmap\n",
    "seed = len(train_noisy) + idx + 1\n",
    "\n",
    "print(idx), print(seed), len(train_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c26bdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = infodata[infodata['seed']==seed]\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93583d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroai.tools.utils import *\n",
    "\n",
    "binning = 200\n",
    "pixelsize = (2 * row['fov'].values[0]) / binning\n",
    "point_ref = (binning / 2) + (pixelsize / 2)\n",
    "w = set_wcs(point_ra=row['point_ra'].values[0], point_dec=row['point_dec'].values[0], \n",
    "            point_ref=point_ref, pixelsize=pixelsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba927e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "radius_deg = 0.2\n",
    "radius_pix = radius_deg/0.025\n",
    "figsize = (10, 10)\n",
    "histsize = (8, 8)\n",
    "fs = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f070e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOISY\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111, projection=w)\n",
    "    \n",
    "img = ax.imshow(test_noisy[idx], vmin=0, vmax=1)\n",
    "ax.coords['ra'].set_format_unit(u.deg)\n",
    "ax.coords['dec'].set_format_unit(u.deg)\n",
    "ax.set_ylabel('Declination [deg]', fontsize=fs)\n",
    "ax.set_xlabel('Right Ascension [deg]', fontsize=fs)\n",
    "#ax.set_title(f'noisy map {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_sim_noisy.png')\n",
    "plt.show()\n",
    "\n",
    "# CLEAN\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111, projection=w)\n",
    "\n",
    "img = ax.imshow(test_clean[idx], vmin=0, vmax=1)\n",
    "ax.coords['ra'].set_format_unit(u.deg)\n",
    "ax.coords['dec'].set_format_unit(u.deg)\n",
    "ax.set_ylabel('Declination [deg]', fontsize=fs)\n",
    "ax.set_xlabel('Right Ascension [deg]', fontsize=fs)\n",
    "#ax.set_title(f'clean map {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_sim_STD.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333b7c38",
   "metadata": {},
   "source": [
    "## Load model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ebf43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(f'../models/crta_models/{cnn_name}.keras')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61948fb3",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3bd850",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc02e6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEAN\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111, projection=w)\n",
    "\n",
    "img = ax.imshow(predictions[idx], vmin=0, vmax=1)\n",
    "ax.coords['ra'].set_format_unit(u.deg)\n",
    "ax.coords['dec'].set_format_unit(u.deg)\n",
    "ax.set_ylabel('Declination [deg]', fontsize=fs)\n",
    "ax.set_xlabel('Right Ascension [deg]', fontsize=fs)\n",
    "#ax.set_title(f'denoised map {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_cnn_clean_cnn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325f0df7",
   "metadata": {},
   "source": [
    "# Revert normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ddc87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from astropy.table import Table\n",
    "from astroai.tools.utils import revert_normalise_heatmap\n",
    "from astroai.tools.utils import extract_heatmap_from_table, normalise_heatmap\n",
    "\n",
    "smooth = 5\n",
    "binning = 200\n",
    "original = f'{path}/dl3_{zenith}_irf/crab_{seed:05d}.fits'\n",
    "original_heatmap = Table.read(original, hdu=1).to_pandas()\n",
    "original_heatmap = extract_heatmap_from_table(original_heatmap, trange=[0, 100], smoothing=smooth, nbins=binning)\n",
    "revert_noisy_heatmap = revert_normalise_heatmap(test_noisy[idx], original_heatmap)\n",
    "revert_cnn_heatmap = revert_normalise_heatmap(predictions[idx], original_heatmap)\n",
    "\n",
    "# DL3\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111, projection=w)\n",
    "\n",
    "img = ax.imshow(revert_noisy_heatmap)\n",
    "ax.coords['ra'].set_format_unit(u.deg)\n",
    "ax.coords['dec'].set_format_unit(u.deg)\n",
    "ax.set_ylabel('Declination [deg]', fontsize=fs)\n",
    "ax.set_xlabel('Right Ascension [deg]', fontsize=fs)\n",
    "#ax.set_title(f'simulated map {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_dl3_noisy.png')\n",
    "plt.show()\n",
    "\n",
    "# REVERTED\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111, projection=w)\n",
    "\n",
    "img = ax.imshow(revert_cnn_heatmap)\n",
    "ax.coords['ra'].set_format_unit(u.deg)\n",
    "ax.coords['dec'].set_format_unit(u.deg)\n",
    "ax.set_ylabel('Declination [deg]', fontsize=fs)\n",
    "ax.set_xlabel('Right Ascension [deg]', fontsize=fs)\n",
    "#ax.set_title(f'denoised map {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_cnn_reverted.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5e393",
   "metadata": {},
   "outputs": [],
   "source": [
    "revert_ctools_heatmap = revert_normalise_heatmap(test_clean[idx], original_heatmap)\n",
    "\n",
    "# REVERTED\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111, projection=w)\n",
    "\n",
    "img = ax.imshow(revert_ctools_heatmap)\n",
    "ax.coords['ra'].set_format_unit(u.deg)\n",
    "ax.coords['dec'].set_format_unit(u.deg)\n",
    "ax.set_ylabel('Declination [deg]', fontsize=fs)\n",
    "ax.set_xlabel('Right Ascension [deg]', fontsize=fs)\n",
    "#ax.set_title(f'clean map {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_sim_reverted.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e5678",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(original_heatmap), np.max(revert_ctools_heatmap), np.max(revert_cnn_heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5e9bec",
   "metadata": {},
   "source": [
    "# Plot loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30abce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model.evaluate(test_noisy, test_clean, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba077b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = np.load(f'../models/crta_models/{cnn_name}_history.npy', allow_pickle='TRUE').item()\n",
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21874c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=histsize)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "ax.plot(history['loss'][:25], ls='--', label='training')\n",
    "ax.plot(history['val_loss'][:25], ls='-.', label = 'validation')\n",
    "ax.set_xlabel('Epoch', fontsize=fs)\n",
    "ax.set_ylabel('Loss', fontsize=fs)\n",
    "#ax.set_title('loss function', fontsize=fs*1.5)\n",
    "ax.set_ylim([0.35,0.7])\n",
    "ax.grid()\n",
    "ax.legend(fontsize=fs)\n",
    "\n",
    "plt.show()\n",
    "fig.savefig(f'img/cleaner_loss_FINAL.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67dd98",
   "metadata": {},
   "source": [
    "# Create SRC and PNT coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9958d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroai.tools.utils import set_wcs\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "binning = 200\n",
    "pixelsize = (2 * row['fov'].values[0]) / binning\n",
    "point_ref = (binning / 2) + (pixelsize / 2)\n",
    "w = set_wcs(point_ra=row['point_ra'].values[0], point_dec=row['point_dec'].values[0], \n",
    "            point_ref=point_ref, pixelsize=pixelsize)\n",
    "point_ref, pixelsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a844ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_x, source_y = w.world_to_pixel(SkyCoord(row['source_ra'].values[0], row['source_dec'].values[0], \n",
    "                                               unit='deg', frame='icrs'))\n",
    "point_x, point_y = w.world_to_pixel(SkyCoord(row['point_ra'].values[0], row['point_dec'].values[0], \n",
    "                                             unit='deg', frame='icrs'))\n",
    "\n",
    "source_x, source_y, point_x, point_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ea159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_pix = {'ra': source_x, 'dec': source_y}\n",
    "point_pix = {'ra': point_x, 'dec': point_y}\n",
    "source_deg = {'ra': row['source_ra'].values[0], 'dec': row['source_dec'].values[0]}\n",
    "point_deg = {'ra': row['point_ra'].values[0], 'dec': row['point_dec'].values[0]}\n",
    "\n",
    "source_pix, point_pix, source_deg, point_deg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62431c6a",
   "metadata": {},
   "source": [
    "# Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e82525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the all DS NOISY\n",
    "#ds['DS3'] = model.predict(np.concatenate((train_noisy, test_noisy)))\n",
    "\n",
    "residuals = {'STD': [], 'CNN': []}\n",
    "\n",
    "for noisy, clean, pred in zip(test_noisy, test_clean, predictions):\n",
    "    residuals['STD'].append(noisy - clean)\n",
    "    residuals['CNN'].append(noisy - pred)\n",
    "    \n",
    "len(residuals['STD']), len(residuals['CNN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d9a901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESIDUALS STD\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "img = ax.imshow(np.flipud(residuals['STD'][idx]), vmin=0, vmax=1)\n",
    "ax.set_ylabel('Declination [deg]', fontsize=fs)\n",
    "ax.set_xlabel('Right Ascension [deg]', fontsize=fs)\n",
    "#ax.set_title(f'simulated {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_residuals_sim.png')\n",
    "plt.show()\n",
    "\n",
    "# RESIDUALS CNN\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "img = ax.imshow(np.flipud(residuals['CNN'][idx]), vmin=0, vmax=1)\n",
    "ax.set_ylabel('Declination [deg]', fontsize=fs)\n",
    "ax.set_xlabel('Right Ascension [deg]', fontsize=fs)\n",
    "#ax.set_title(f'denoised {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_residuals_cnn.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80311cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = residuals['STD'][idx] - residuals['CNN'][idx]\n",
    "\n",
    "# RESIDUALS STD\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "img = ax.imshow(np.flipud(diff), vmin=0, vmax=1)\n",
    "ax.set_ylabel('Declination [deg]', fontsize=fs)\n",
    "ax.set_xlabel('Right Ascension [deg]', fontsize=fs)\n",
    "#ax.set_title(f'simulated {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_residuals_diff.png')\n",
    "plt.show()\n",
    "\n",
    "# RESIDUALS CNN\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "img = ax.imshow(np.flipud(diff))\n",
    "ax.set_ylabel('Declination [deg]', fontsize=fs)\n",
    "ax.set_xlabel('Right Ascension [deg]', fontsize=fs)\n",
    "#ax.set_title(f'denoised map {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_residuals_vdiff.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32260ed1",
   "metadata": {},
   "source": [
    "# Histograms on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbafbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_residual = {'STD': [], 'CNN': []}\n",
    "for std, cnn in zip(residuals['STD'], residuals['CNN']):\n",
    "    sum_residual['STD'].append(np.sum(std))\n",
    "    sum_residual['CNN'].append(np.sum(cnn))\n",
    "\n",
    "sum_cleaned = {'STD': [], 'CNN': []}\n",
    "for std, cnn in zip(test_clean, predictions):\n",
    "    sum_cleaned['STD'].append(np.sum(std))\n",
    "    sum_cleaned['CNN'].append(np.sum(cnn))\n",
    "    \n",
    "sum_original_and_diff = {'NOISY': [], 'DIFF': []}\n",
    "for orig, std, cnn in zip(test_noisy, residuals['STD'], residuals['CNN']):\n",
    "    sum_original_and_diff['NOISY'].append(np.sum(orig))\n",
    "    sum_original_and_diff['DIFF'].append(np.sum(std - cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e58ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "\n",
    "colors = ['blue', 'red']\n",
    "hatches = ['\\\\', '//']\n",
    "legends = [mpatches.Patch(facecolor='none', edgecolor=colors[0], hatch=hatches[0]), \n",
    "           mpatches.Patch(facecolor='none', edgecolor=colors[1], hatch=hatches[1])]\n",
    "\n",
    "# original hist\n",
    "fig = plt.figure(figsize=histsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "data = sum_original_and_diff['NOISY']\n",
    "#ax.set_title('simulations (noisy)', fontsize=fs*1.5)\n",
    "n, bins, patches = ax.hist(data, 20, density=False, histtype='step', color='green')\n",
    "#ax.tick_params(axis='both', labelsize=fs/2)\n",
    "ax.set_ylabel('samples in datatset', fontsize=fs)\n",
    "ax.set_xlabel('FoV integrated counts', fontsize=fs)\n",
    "ax.grid() \n",
    "\n",
    "for patch, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch, hatch=hatch)\n",
    "\n",
    "fig.savefig(f'img/cleaner_ds_FINAL_noisy_counts.png')\n",
    "plt.show()\n",
    "\n",
    "# cumulative counts hist\n",
    "fig = plt.figure(figsize=histsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "data = (sum_cleaned['STD'], sum_cleaned['CNN'])\n",
    "#ax.set_title('simulations vs predictions (clean)', fontsize=fs*1.5)\n",
    "n, bins, patches = ax.hist(data, 20, density=False, histtype='step', color=colors, label=['standard', 'cnn'])\n",
    "#ax.tick_params(axis='both', labelsize=fs/2)\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('FoV integrated counts', fontsize=fs)\n",
    "ax.legend(fontsize=fs)\n",
    "ax.grid()\n",
    "\n",
    "for patch, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch, hatch=hatch)\n",
    "\n",
    "fig.savefig(f'img/cleaner_ds_FINAL_clean_counts.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2763b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'red']\n",
    "\n",
    "# residual hist\n",
    "fig = plt.figure(figsize=histsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "data = (sum_residual['STD'], sum_residual['CNN'])\n",
    "#ax.set_title('residuals', fontsize=fs*1.5)\n",
    "n, bins, patches = ax.hist(data, 20, density=False, histtype='step', color=colors, label=['standard', 'cnn'])\n",
    "#ax.tick_params(axis='both', labelsize=fs/2)\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('removed background counts', fontsize=fs)\n",
    "ax.legend(fontsize=fs)\n",
    "ax.grid()\n",
    "\n",
    "for patch, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch, hatch=hatch)\n",
    "\n",
    "fig.savefig(f'img/cleaner_ds_FINAL_residuals_counts.png')\n",
    "plt.show()\n",
    "\n",
    "# residual diff hist\n",
    "fig = plt.figure(figsize=histsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "data = sum_original_and_diff['DIFF']\n",
    "#ax.set_title('residuals', fontsize=fs*1.5)\n",
    "n, bins, patches = ax.hist(data, 20, density=False, histtype='step', color='g')\n",
    "#ax.tick_params(axis='both', labelsize=fs/2)\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('removed background counts (absolute difference)', fontsize=fs)\n",
    "ax.grid()\n",
    "\n",
    "for patch, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch, hatch=hatch)\n",
    "\n",
    "fig.savefig(f'img/cleaner_ds_FINAL_residuals_counts_diff.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25c42cd",
   "metadata": {},
   "source": [
    "# extract on source counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17311be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Circle\n",
    "\n",
    "x, y = source_x, source_y\n",
    "xy = source_x, source_y\n",
    "radius_pix = 0.2/0.025\n",
    "\n",
    "# STD cleaning\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow(test_clean[idx], vmin=0, vmax=1)\n",
    "ax.add_patch(plt.Circle(xy, radius=radius_pix, edgecolor='r', facecolor='none'))\n",
    "ax.set_ylabel('y [pixel]', fontsize=fs)\n",
    "ax.set_xlabel('x [pixel]', fontsize=fs)\n",
    "#ax.set_title(f'clean map {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('simulated counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_sim_on_region.png')\n",
    "plt.show()\n",
    "\n",
    "# CNN cleaning\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "ax.imshow(predictions[idx], vmin=0, vmax=1)\n",
    "ax.add_patch(plt.Circle(xy, radius=radius_pix, edgecolor='r', facecolor='none'))\n",
    "ax.set_ylabel('y [pixel]', fontsize=fs)\n",
    "ax.set_xlabel('x [pixel]', fontsize=fs)\n",
    "#ax.set_title(f'denoised map {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_cnn_on_region.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddaa0c9",
   "metadata": {},
   "source": [
    "# Create on source mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b261a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_circular_mask(h, w, center=None, radius=None):\n",
    "\n",
    "    if center is None: # use the middle of the image\n",
    "        center = (int(w/2), int(h/2))\n",
    "    if radius is None: # use the smallest distance between the center and image walls\n",
    "        radius = min(center[0], center[1], w-center[0], h-center[1])\n",
    "\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius\n",
    "    return mask\n",
    "\n",
    "# STD cleaning\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "h, w = test_clean[idx].shape[:2]\n",
    "mask = create_circular_mask(h, w, center=(x, y), radius=radius_pix)\n",
    "masked_img1 = test_clean[idx].copy()\n",
    "masked_img1[~mask] = 0\n",
    "\n",
    "ax.imshow(np.flipud(masked_img1))\n",
    "ax.set_ylabel('y [pixel]', fontsize=fs)\n",
    "ax.set_xlabel('x [pixel]', fontsize=fs)\n",
    "#ax.set_title(f'simulated {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_sim_on_mask.png')\n",
    "plt.show()\n",
    "\n",
    "# CNN cleaning\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "h, w = predictions[idx].shape[:2]\n",
    "mask = create_circular_mask(h, w, center=(x, y), radius=radius_pix)\n",
    "masked_img2 = predictions[idx].copy()\n",
    "masked_img2[~mask] = 0\n",
    "\n",
    "ax.imshow(np.flipud(masked_img2))\n",
    "ax.set_ylabel('y [pixel]', fontsize=fs)\n",
    "ax.set_xlabel('x [pixel]', fontsize=fs)\n",
    "#ax.set_title(f'denoised {seed}', fontsize=fs*1.5)\n",
    "\n",
    "cb = fig.colorbar(img, ax=ax, shrink=0.8)\n",
    "ax.tick_params(axis='both', labelsize=fs)\n",
    "cb.ax.tick_params(labelsize=fs)\n",
    "cb.set_label('normalised counts', fontsize=fs)\n",
    "\n",
    "fig.savefig(f'img/{seed}_cleaner_cnn_on_mask.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e33145",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(masked_img1), np.sum(masked_img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce5fca",
   "metadata": {},
   "source": [
    "# Histograms on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e987513",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_on_region = {'STD': [], 'CNN': [], 'AP_EXCESS': [], 'DIFF': []}\n",
    "\n",
    "s = len(train_noisy)\n",
    "for std, cnn in zip(test_clean, predictions):\n",
    "    s += 1 \n",
    "    row = infodata[infodata['seed']==s]\n",
    "    # sky coordinates\n",
    "    source_deg = {'ra': row['source_ra'].values[0], 'dec': row['source_dec'].values[0]}\n",
    "    point_deg = {'ra': row['point_ra'].values[0], 'dec': row['point_dec'].values[0]}\n",
    "    # pixel coordinates\n",
    "    w = set_wcs(point_ra=row['point_ra'].values[0], point_dec=row['point_dec'].values[0], \n",
    "            point_ref=point_ref, pixelsize=pixelsize)\n",
    "    x, y = w.world_to_pixel(SkyCoord(row['source_ra'].values[0], row['source_dec'].values[0], \n",
    "                                                   unit='deg', frame='icrs'))\n",
    "    # ON counts with STD cleaning\n",
    "    h, w = std.shape[:2]\n",
    "    mask = create_circular_mask(h, w, center=(y, x), radius=radius_pix)\n",
    "    masked_std = std.copy()\n",
    "    masked_std[~mask] = 0\n",
    "\n",
    "    # ON counts with CNN cleaning\n",
    "    h, w = cnn.shape[:2]\n",
    "    mask = create_circular_mask(h, w, center=(y, x), radius=radius_pix)\n",
    "    masked_cnn = cnn.copy()\n",
    "    masked_cnn[~mask] = 0\n",
    "    \n",
    "    sum_on_region['STD'].append(np.sum(masked_std))\n",
    "    sum_on_region['CNN'].append(np.sum(masked_cnn))\n",
    "    #sum_on_region['AP_EXCESS'].append(dl3_ph['excess'])\n",
    "    sum_on_region['DIFF'].append(np.sum(masked_std - masked_cnn))\n",
    "\n",
    "sum_on_region.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'red'] \n",
    "\n",
    "# cumulative counts hist\n",
    "fig = plt.figure(figsize=histsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "data = (sum_on_region['STD'], sum_on_region['CNN']) \n",
    "#ax.set_title('residuals', fontsize=fs*1.5)\n",
    "n, bins, patches = ax.hist(data, 20, density=False, histtype='step', color=colors, label=['standard', 'cnn'])\n",
    "#ax.tick_params(axis='both', labelsize=fs/2)\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('excess counts', fontsize=fs)\n",
    "ax.legend(fontsize=fs)\n",
    "ax.grid()\n",
    "\n",
    "for patch, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch, hatch=hatch)\n",
    "\n",
    "fig.savefig(f'img/cleaner_ds_FINAL_on_counts.png')\n",
    "plt.show()\n",
    "\n",
    "# residual hist\n",
    "fig = plt.figure(figsize=histsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "data = sum_on_region['DIFF']\n",
    "#ax.set_title('residuals', fontsize=fs*1.5)\n",
    "n, bins, patches = ax.hist(data, 20, density=False, histtype='step', color='g')\n",
    "#ax.tick_params(axis='both', labelsize=fs/2)\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('excess counts (absolute error)', fontsize=fs)\n",
    "ax.grid()\n",
    "\n",
    "for patch, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch, hatch=hatch)\n",
    "\n",
    "fig.savefig(f'img/cleaner_ds_FINAL_on_counts_diff.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7012acd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'red'] \n",
    "\n",
    "# cumulative counts hist\n",
    "fig = plt.figure(figsize=histsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "data = np.abs((np.array(sum_on_region['CNN']) - np.array(sum_on_region['STD']))/np.array(sum_on_region['STD']))*100\n",
    "#ax.set_title('residuals', fontsize=fs*1.5)\n",
    "n, bins, patches = ax.hist(data, 20, density=False, histtype='step', color='g')\n",
    "#ax.tick_params(axis='both', labelsize=fs/2)\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('excess counts (percent error)', fontsize=fs)\n",
    "#ax.legend(fontsize=fs)\n",
    "ax.grid()\n",
    "#ax.set_xlim([-0.2,100])\n",
    "\n",
    "for patch, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch, hatch=hatch)\n",
    "\n",
    "fig.savefig(f'img/cleaner_ds_FINAL_excess_percentage_error.png')\n",
    "plt.show()\n",
    "\n",
    "# residual hist\n",
    "fig = plt.figure(figsize=histsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "data = np.abs((np.array(sum_residual['CNN']) - np.array(sum_residual['STD']))/np.array(sum_residual['STD']))*100\n",
    "#ax.set_title('residuals', fontsize=fs*1.5)\n",
    "n, bins, patches = ax.hist(data, 20, density=False, histtype='step', color='g')\n",
    "#ax.tick_params(axis='both', labelsize=fs/2)\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('removed background counts (percent difference)', fontsize=fs)\n",
    "ax.grid()\n",
    "ax.set_xlim([-20,1500])\n",
    "\n",
    "for patch, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch, hatch=hatch)\n",
    "\n",
    "fig.savefig(f'img/cleaner_ds_FINAL_residuals_percentage_error.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196451a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['blue', 'red'] \n",
    "\n",
    "# cumulative counts hist\n",
    "fig = plt.figure(figsize=histsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "data = np.abs((np.array(sum_on_region['CNN']) - np.array(sum_on_region['STD']))/np.array(sum_on_region['STD']))\n",
    "#ax.set_title('residuals', fontsize=fs*1.5)\n",
    "n, bins, patches = ax.hist(data, 20, density=False, histtype='step', color='g')\n",
    "#ax.tick_params(axis='both', labelsize=fs/2)\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('excess counts (relative error)', fontsize=fs)\n",
    "#ax.legend(fontsize=fs)\n",
    "ax.grid()\n",
    "ax.set_xlim([-0.2,5])\n",
    "\n",
    "for patch, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch, hatch=hatch)\n",
    "\n",
    "fig.savefig(f'img/cleaner_ds_FINAL_excess_relative_error.png')\n",
    "plt.show()\n",
    "\n",
    "# residual hist\n",
    "fig = plt.figure(figsize=histsize)\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "data = np.abs((np.array(sum_residual['CNN']) - np.array(sum_residual['STD']))/np.array(sum_residual['STD']))\n",
    "#ax.set_title('residuals', fontsize=fs*1.5)\n",
    "n, bins, patches = ax.hist(data, 20, density=False, histtype='step', color='g')\n",
    "#ax.tick_params(axis='both', labelsize=fs/2)\n",
    "ax.set_ylabel('samples in dataset', fontsize=fs)\n",
    "ax.set_xlabel('removed background counts (relative difference)', fontsize=fs)\n",
    "ax.grid()\n",
    "ax.set_xlim([-0.2,10])\n",
    "\n",
    "for patch, hatch in zip(patches, hatches):\n",
    "    plt.setp(patch, hatch=hatch)\n",
    "\n",
    "fig.savefig(f'img/cleaner_ds_FINAL_residuals_relative_error.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f892377",
   "metadata": {},
   "source": [
    "# Errors Excess Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "relerr = np.abs((np.array(sum_on_region['CNN']) - np.array(sum_on_region['STD']))/np.array(sum_on_region['STD']))\n",
    "percerr = np.abs((np.array(sum_on_region['CNN']) - np.array(sum_on_region['STD']))/np.array(sum_on_region['STD']))*100\n",
    "abserr = (np.array(sum_on_region['CNN']) - np.array(sum_on_region['STD']))\n",
    "\n",
    "with open(f'data/error_excess_relative_{zenith}.pickle','wb') as f: pickle.dump(relerr, f, protocol=4)\n",
    "with open(f'data/error_excess_percent_{zenith}.pickle','wb') as f: pickle.dump(percerr, f, protocol=4)\n",
    "with open(f'data/error_excess_absolute_{zenith}.pickle','wb') as f: pickle.dump(abserr, f, protocol=4)\n",
    "\n",
    "np.percentile(relerr, 68)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cbf696",
   "metadata": {},
   "source": [
    "# Errors Background Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "relerr = np.abs((np.array(sum_residual['CNN']) - np.array(sum_residual['STD']))/np.array(sum_residual['STD']))\n",
    "percerr = np.abs((np.array(sum_residual['CNN']) - np.array(sum_residual['STD']))/np.array(sum_residual['STD']))*100\n",
    "abserr = (np.array(sum_residual['CNN']) - np.array(sum_residual['STD']))\n",
    "\n",
    "with open(f'data/error_bkg_relative_{zenith}.pickle','wb') as f: pickle.dump(relerr, f, protocol=4)\n",
    "with open(f'data/error_bkg_percent_{zenith}.pickle','wb') as f: pickle.dump(percerr, f, protocol=4)\n",
    "with open(f'data/error_bkg_absolute_{zenith}.pickle','wb') as f: pickle.dump(abserr, f, protocol=4)\n",
    "\n",
    "100 - np.percentile(relerr, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5344e5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1001cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e739d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285d9772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c424ad9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2603ad4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1986e0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f43f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astroai",
   "language": "python",
   "name": "astroai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
